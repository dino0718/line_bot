from langchain.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
from core.config import Config

# åˆå§‹åŒ– GPT-4 LLM
llm = ChatOpenAI(
    model_name="gpt-4",
    openai_api_key=Config.OPENAI_API_KEY,
    temperature=0.7  # èª¿æ•´æº«åº¦ä»¥æ”¹è®Šå›æ‡‰çš„å‰µæ„ç¨‹åº¦
)

def chat_with_gpt(user_input):
    """
    ä½¿ç”¨ LangChain çš„ GPT-4 æ¨¡å‹é€²è¡Œå°è©±
    """
    try:
        response = llm([
            SystemMessage(content="ä½ æ˜¯Lumeï¼ˆè·¯æ¢…ï¼‰ï¼Œä¸€å€‹æº«æš–å’Œå°ˆæ¥­çš„å¿ƒç†é™ªä¼´è€…ï¼Œè«‹ä»¥æœ‹å‹çš„èªæ°£å›ç­”å•é¡Œä¸¦ä¸”ä½¿ç”¨äººé¡æœƒç”¨çš„ç”¨è©ã€é—œå¿ƒä¾†å›å¾©ã€‚"),
            HumanMessage(content=user_input)
        ])
        return response.content.strip()
    except Exception as e:
        print(f"GPT-4 API éŒ¯èª¤ï¼š{e}")
        return "æŠ±æ­‰ï¼Œæˆ‘ç›®å‰ç„¡æ³•å›æ‡‰ï¼Œè«‹ç¨å¾Œå†è©¦ ğŸ™"
